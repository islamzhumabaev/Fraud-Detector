## Загрузка и предварительная обработка данных

### Источник данных
Данные взяты с Kaggle: [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud). Датасет содержит транзакции по кредитным картам, с меткой, указывающей на наличие или отсутствие мошенничества.

### Размерность
- Общее количество записей: **284 807**
- Количество признаков: **31**

### Распределение классов
Целевая переменная `Class`:
- `0` — нормальная транзакция
- `1` — мошенническая транзакция

Распределение:
- Нормальных транзакций: **284 315**
- Мошеннических транзакций: **492**

Датасет имеет выраженный дисбаланс классов, что необходимо учитывать при обучении моделей.

---

### Обработка дисбаланса
Для сбалансированного анализа и обучения была выполнена равномерная выборка:
- Случайным образом выбраны 492 нормальные транзакции
- Объединены с 492 мошенническими транзакциями

Итоговый сбалансированный датасет содержит **984 записи** — по 50% на каждый класс.

---

### Проверка данных
- Убедились в отсутствии пропущенных значений (`isnull().sum()`)
- Проведён базовый обзор данных с помощью `.info()` и `.describe()` для ключевых признаков (например, `Amount` в мошеннических транзакциях)



## Обучение моделей и подбор гиперпараметров

### Подготовка признаков

- Целевая переменная: `Class`
- Признаки: все остальные колонки (`V1`–`V28`, `Amount`, `Time`)
- Данные разделены на обучающую и тестовую выборки с использованием стратификации (`stratify=Y`)
- Для признака `Amount` применено стандартное масштабирование с помощью `StandardScaler`

---

### Обученные модели

Были обучены следующие классификаторы:

1. **Logistic Regression**
2. **K-Nearest Neighbors**
3. **Decision Tree** (c подбором гиперпараметров)
4. **Random Forest** (GridSearchCV)
5. **Gradient Boosting** (GridSearchCV)
6. **AdaBoost** (на базе DecisionTree, GridSearchCV)
7. **Support Vector Machine (SVC)** (GridSearchCV)
8. **LightGBM** (GridSearchCV)

---

### Подбор гиперпараметров (GridSearchCV)

Для большинства моделей использовался `GridSearchCV` (3-fold cross-validation) с целью нахождения наилучших параметров. Были протестированы комбинации следующих гиперпараметров:

- **Decision Tree**: `max_depth`, `min_samples_split`, `min_samples_leaf`, `criterion`
- **Random Forest**: `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`, `criterion`
- **Gradient Boosting**: `n_estimators`, `learning_rate`, `max_depth`, `min_samples_split`, `min_samples_leaf`
- **AdaBoost**: `n_estimators`, `learning_rate` (базовая модель — Decision Tree с лучшими параметрами)
- **SVC**: `C`, `kernel`, `gamma`
- **LightGBM**: `n_estimators`, `learning_rate`, `max_depth`, `num_leaves`

Каждая модель была обучена на обучающей выборке и протестирована на тестовой выборке. Предсказания сохранены в виде списка `collection`, где каждый элемент — предсказания соответствующей модели.

---

### Промежуточный вывод

- Использование кросс-валидации позволило оптимизировать параметры и избежать переобучения.
- Было обеспечено единое масштабирование и контроль за случайностью за счёт установки `random_state`.
- Модели построены с учётом высокой чувствительности задачи (обнаружение мошенничества), что важно для последующего анализа метрик.


## Оценка моделей и визуализация результатов

Для каждой обученной модели были рассчитаны основные метрики:

- **Accuracy** — доля правильно классифицированных примеров
- **Precision** — точность для положительного класса (мошенничество)
- **Recall** — полнота для положительного класса
- **Confusion Matrix** — матрица ошибок, показывающая распределение предсказаний

### Метрики по моделям

| Model               | Accuracy | Precision | Recall  |
|---------------------|----------|-----------|---------|
| Logistic Regression | 0.944    | 0.898     | 0.989   |
| KNN                 | 0.675    | 0.714     | 0.660   |
| Decision Tree       | 0.893    | 0.867     | 0.914   |
| SVC                 | 0.913    | 0.827     | 1.000   |
| Random Forest       | 0.924    | 0.867     | 0.977   |
| Gradient Boosting   | 0.929    | 0.878     | 0.977   |
| AdaBoost            | 0.929    | 0.878     | 0.977   |
| LightGBM            | 0.924    | 0.867     | 0.977   |

### Визуализация confusion matrix

Для каждой модели построена матрица ошибок с помощью `seaborn.heatmap`, где:

- Строки — реальные значения (`Actual`)
- Столбцы — предсказанные значения (`Predicted`)
- Диагональные элементы отражают верные предсказания
- Недостаток recall у KNN и Logistic Regression заметен по числу FN (False Negative)

### Выводы

- **Gradient Boosting**, **AdaBoost** и **LightGBM** показали лучшие результаты по метрикам полноты и точности, особенно в задаче выявления мошеннических транзакций.
- **SVC** продемонстрировала идеальную полноту (Recall = 1.0), но чуть меньшую точность.
- **KNN** оказался наименее подходящим для данной задачи, особенно по recall.

Выбор модели зависит от приоритетов — если критична минимизация пропущенных случаев мошенничества, то предпочтение стоит отдать моделям с максимальным recall.
